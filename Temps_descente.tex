\documentclass[a4paper,10pt]{article}
\usepackage[]{inputenc, amssymb, amsmath, amsthm, graphicx, hyperref}


%opening
\title{Calcul d'un temps de descente}
\author{DAVY L\'eo, CARPENTIER Florian \\
\small Universit\'e Paul Sabatier - Toulouse 3 \\
\small L2 Parcours Sp\'ecial Math\'ematiques}


\begin{document}

\maketitle
\newtheorem{theorem}{Theor\`eme}
\begin{abstract}
Nous allons ici vous pr\'esenter la math\'ematisation de l'un des sujets du projet. Celui-ci a des applications concr\`etes, notamment dans le milieu de l'a\'eronautique, par exemple
pour calculer les meilleures trajectoires de descente vers les a\'eroports. Cependant, la r\'esolution de ce probl\`eme date de bien avant l'a\'eronautique, en 1638, Galil\'ee est le premier \`a s'int\'eresser
\`a ce probl\`eme. Jean Bernoulli sera le premier \`a r\'esoudre ce probl\`eme en 1696, des solutions de Newton, Leibnitz et Jacques Bernoulli seront aussi retenues \`a la suite d'un d\'efi lanc\'e
par Jean Bernoulli. La solution au probl\`eme est appel\'ee courbe de brachistochrone, c'est un arc de cycloïde. Ces \'etudes auront permis de d\'evelopper le calcul diff\'erentiel et variationnel.
\end{abstract}
\section{\'Etude m\'ecanique du probl\`eme}
Nous allons maintenant \'etudier une approche m\'ecanique du probl\`eme. On peut l'assimiler \`a une bille l\^ach\'ee dans un toboggan avec certains param\`etres, le toboggan d\'emarre en $(0,0)$
et s'arrête en $(1,1)$, (sans pertes de g\'en\'eralit\'es). On a donc $y : [0,1]\longrightarrow \mathbb{R}$ avec $y(0) = 0, y(1) = 1$ et $y$ continue. La bille est \'egalement l\^ach\'ee sans vitesse initiale.
On l'assimile \`a un point de masse m et on n\'egligera les frottements. L'abscisse curviligne de la bille sera not\'ee $S$.
\newline
On applique \`a ce syst\`eme un PFD et on remarque que la r\'eaction du toboggan ne travaille pas. On a ainsi :
\begin{equation}
 E_c(t) = \frac{1}{2}m\Big(\frac{dS}{dt}\Big)^2, \text{ et } E_p(t) = -mgy(x(t))
\end{equation}
Avec la loi de conservation de l'\'energie et les conditions initales on a :
\begin{equation}
 E_c(t) + E_p(t) = E_c(0) + E_p(0) = 0 = \frac{1}{2}m\Big(\frac{dS}{dt}\Big)^2 - mgy(x(t)) 
\end{equation}
\begin{equation}
 \frac{dS}{dt}=\sqrt{\frac{2mgy}{m}} = \sqrt{2gy} = S'(t)
\end{equation}
On obtient donc, avec un changement de variable la formule suivante :
\begin{equation}
\label{integrale}
 T(y) - T(0) = \int_0^{T(y)} dt = \int_0^{l(y)} \frac{dS}{\sqrt{2gy}}
\end{equation}
Par ailleurs, avec le th\'eor\`eme de Pythagore on obtient :
\begin{equation}
 dS = \sqrt{(dx)^2 + (dy)^2} = \sqrt{1 + \Big(\frac{dy}{dx}\Big)^2}dx = \sqrt{1 + \Big(y'(x)\Big)^2}dx
\end{equation}
Avec l'expression pr\'ecedente et \ref{integrale} on obtient finalement :
\begin{equation}
 T(y) = \int_0^1 \frac{\sqrt{1 + \Big(y'(x)\Big)^2}}{\sqrt{2gy}}dx
\end{equation}
Cependant l'expression pr\'ecedente pr\'sente des probl\`emes de singularit\'e en 0. En effet, on sait, qu'en 0, on a $y(0) = 0$ donc l'expression \`a int\'egrer  va varier tr\`es rapidement
\`a proximit\'e de l'origine. Mais aussi, le calcul va d\'ependre de la d\'eriv\'ee de $y$ qui n'est pas suppos\'ee connue. Afin de r\'esoudre cette \'equation, qui n'admet pas forc\'ement de solution
analytique, il faut donc recourir \`a des m\'ethodes num\'eriques. 

\section{M\'ethode de r\'esolution ouverte}
La singularit\'e apparaissant en 0, on va utiliser une m\'ethode dite ``ouverte'' dans laquelle nous allons \'etudier l'int\'egrale sans calculer la valeur de la fonction \`a int\'egrer en 0 en utilisant
la m\'ethode vue en cours du point milieu.
\newline
On supposera dans cette partie que $y\in \mathcal{C}^1$ et que $y(x) > 0$, pour tout $x \neq 0$.
Pour simplifier les notations, on pose
\begin{equation}
 f(x) := \frac{\sqrt{1+(y'(x))^2}}{\sqrt{2gy(x)}}
\end{equation}
En notant $T_N(y)$ la valeur de $T(y)$ avec la m\'ethode du point milieu avec un pas de $1/N$ on obtient:
\begin{equation}
 T(y) \simeq T_N(y) := \frac{1}{N}\sum_{i = 0}^{N-1} f\Big(\frac{2i + 1}{2N}\Big)
\end{equation}
\begin{theorem}
 Si $f$ est de la forme $f(x) = x^{-\beta} + g(x)$ avec $g$ une fonction r\'eguli\`ere et $0 < \beta < 1$, Alors la m\'ethode du point milieu est d'ordre $1 - \beta$. 
\end{theorem}

\underline{Remarque : } $g$ r\'eguli\`ere signifie que $g$ est, au moins, partout $\mathcal{C}^1$, la fonction f peut donc repr\'esenter assez fid\`element un grand nombre de fonctions.
\begin{proof}
 Nous souhaitons mesurer l'erreur entre la m\'ethode exacte et la m\'ethode du point milieu.
 \begin{equation}
  |T(y) - T_N(y)| = |\int_0^\frac{1}{N}f(x)dx - \frac{1}{N}f\Big(\frac{1}{2N}\Big) + \int_\frac{1}{N}^1f(x)dx - \frac{1}{N}\sum_{i=1}^{N-1}\Big(\frac{2i + 1}{2N}\Big)|
 \end{equation}
 On applique l'in\'egalit\'e triangulaire
 \begin{equation}
  |T(y) - T_N(y)| \leq |\int_0^\frac{1}{N}f(x)dx - \frac{1}{N}f\Big(\frac{1}{2N}\Big)| + |\int_\frac{1}{N}^1f(x)dx - \frac{1}{N}\sum_{i=1}^{N-1}\Big(\frac{2i + 1}{2N}\Big)|
 \end{equation}
Par ailleurs,
\begin{equation}
\label{firstpart}
 \int_0^{\frac{1}{N}}f(x)dx = \int_0^{\frac{1}{N}} x^{-\beta} + g(x)dx = \frac{(\frac{1}{N})^{-\beta + 1}}{-\beta + 1} + \int_0^{\frac{1}{N}}g(x)dx = \mathcal{O}(N^{\beta - 1})
\end{equation}
On remarque dans l'expression pr\'ecedente qu'il est n\'cessaire d'avoir $\beta \neq 0$ afin de ne pas faire de division par z\'ero.
Il nous reste donc \`a majorer le second terme, d'apr\`es le cours, la m\'ethode du point milieu est d'ordre $p = 1$ et d'apr\`es le th\'eor\`eme 4, il existe une constante $ C > 0$, telle que,
en posant $J_i = [\frac{2i-1}{2N},\frac{2i+1}{2N}], i \in [ 1,..., N-1]$ on obtient :
\begin{equation}
\begin{align}
 |\int_{J_i} f(x)dx - \frac{1}{N}f\Big(\frac{i}{N}\Big)| &\leq C(\frac{1}{N})^3 \sup_{x \in J_i}|f''(x)|\\
						 &\leq \frac{C}{N^3}(\| -\beta(-\beta - 1)x^{-\beta - 2} + g''(x)  \|_{\infty, J_i} \\
						 &\leq C N^{\beta - 1}i^{-\beta - 2} + \|\frac{C}{N^3}g''(x)  \|_{\infty, J_i} \\
\end{align}
\end{equation}
On a aussi :
\begin{equation}
 \begin{align} 
 |\int_\frac{1}{N}^1f(x)dx - \frac{1}{N}\sum_{i=1}^{N-1}f\Big(\frac{2i + 1}{2N}\Big)| &=  |\sum_{i=1}^{N-1}\int_{J_i} f(x)dx - \frac{1}{N}f\Big(\frac{2i + 1}{2N}\Big)|\\
									     &\leq  \sum_{i=1}^{N-1}|\int_{J_i} f(x)dx - \frac{1}{N}f\Big(\frac{2i + 1}{2N}\Big)|\\
									     &\leq C N^{\beta - 1} \sum_{i=1}^{N-1}i^{-\beta - 2} + \frac{C}{N^3}\sum_{i=1}^{N-1} \|g''(x)  \|_{\infty, J_i}
 \end{align}
\end{equation}
Or,
\begin{equation}
 \|g''(x)  \|_{\infty, J_i} \leq \|g''(x)  \|_{\infty, [0,1]}, \forall i
\end{equation}
Donc
\begin{equation}
 \sum_{i=1}^{N-1}\|g''(x)  \|_{\infty, J_i} \leq \sum_{i=1}^{N-1}\|g''(x)  \|_{\infty, [0,1]} = (N-1)\|g''(x)  \|_{\infty, [0,1]} 
\end{equation}
Et par ailleurs,
\begin{equation}
 0 < \sum_{i=1}^{N-1}i^{-\beta - 2} \leq \sum_{i=1}^{N-1}i^{- 2} \leq \sum_{i=1}^{\infty}i^{- 2} = \frac{\pi ^2}{6}  
\end{equation}
finalement :
\begin{equation}
\begin{align}
 |\int_\frac{1}{N}^1f(x)dx - \frac{1}{N}\sum_{i=1}^{N-1}f\Big(\frac{2i + 1}{2N}\Big)| &\leq C N^{\beta - 1} \frac{\pi ^2}{6}  + \frac{C}{N^2}\|g''(x)  \|_{\infty, [0,1]} 
									     &= \mathcal{O}(N^{\beta - 1}) 
\end{align}
\end{equation}
 En combinant \ref{firstpart} et l'expression pr\'ecedente on obtient bien que la m\'ethode est d'ordre $1- \beta$. Le th\'eor\`eme est donc bien d\'emontr\'e.
\end{proof}
Ce r\'esultat nous assure que nous avons au moins une solution num\'erique, cependant , cette m\'ethode n'\'etant pas tr\`es efficace, nous allons essayer dans la suite de trouver une m\'ethode plus efficace.

\section{R\'esolution avec un changement de variable}
Nous allons dans cette partie consid\'erer que le comportement de la fonction $y$ est connu en 0 et est de la forme
\begin{equation}
 y(x)\sim_0 c.x^{\alpha} \text{, avec } \beta = \begin{cases}
						    1 - \frac{\alpha}{2} &\text{, si }\alpha < 1\\
						    \frac{\alpha}{2}	 &\text{, si } 1 < \alpha < 2\\
						 \end{cases}
\end{equation}
Et on pose $x = u^\rho$, avec $\rho = \frac{1}{1 - \beta}$.
\begin{equation}
 \frac{dx}{du} = \rho u^{\rho - 1}
\end{equation}
On a donc
\begin{equation}
 T(y) = \int_0^1f(x)dx = \int_0^1f(u^\rho)\rho u^{\rho - 1} du = \rho \int_0^1f(u^\rho) u^{\rho - 1} du
\end{equation}
On applique maintenant la m\'ethode du point milieu et on obtient directement 
\begin{equation}
 T(y) \simeq \frac{\rho}{N}\sum_{i=0}^{N-1}f\Bigg(\Big(\frac{2i + 1}{2N}\Big)^{\rho}\Bigg)\Big(\frac{2i + 1}{2N}\Big)^{\rho - 1}
\end{equation}
Cette m\'ethode est d'ordre $\rho - 1$.
\section{Comparaison des deux m\'ethodes}
La m\'ethode du changementde variable est plus efficace si 
\begin{equation}
 \rho - 1 = \frac{\beta}{1-\beta} > 1 - \beta
\end{equation}
Comme $0 < \beta < 1$, l'in\'egalit\'e pr\'ecedente est toujours v\'erifi\'ee . Nous allons maintenant comparer les deux m\'ethodes sur des plusieurs exemples.
\newline
\underline{Cas d'un toboggan de type $y(x) = x$}: Dans ce cas on a $\alpha = 1$ et $\beta = \frac{1}{2}$, donc la premi\`ere m\'ethode est d'ordre $\frac{1}{2}$ et la seconde est d'ordre 1. 
\newline
\underline{Cas d'un toboggan de type $y(x) = \sqrt{x}$}: Dans ce cas on a $\alpha = \frac{1}{2}$ et $\beta = \frac{3}{4}$, donc la premi\`ere m\'ethode est d'ordre $\frac{1}{4}$ et la seconde est d'ordre 3.
\newline
\underline{Cas d'un toboggan de type $y(x) = \frac{1}{2}x^{\frac{3}{2}}(5-3x)$}: Dans ce cas on a ( au voisinage de 0 ) $\alpha = \frac{3}{2}$ et $\beta = \frac{3}{4}$, donc la premi\`ere m\'ethode est d'ordre $\frac{1}{4}$ et la seconde est d'ordre 3.
\newline
Ainsi, la seconde m\'ethode est bien plus efficace que la premi\`ere, cela s'explique par le fait que le changement de variable permet d'\'eviter la singularit\'e en 0.


\newpage
\section{Application Num\'erique}

Nous allons dans un premier temps \'etudier la fonction $x \mapsto x$. Par un calcul on peut obtenir la valeur exacte de $T(x \mapsto x) = \frac{2}{\sqrt{10}} \approx 0.63245553203$.
On peut voir ci-dessous les valeurs obtenues avec les m\'ethodes les plus classiques. On peut y observer que la m\'ethode des rectangles \'a gauche est sensiblement plus efficace car elle contient 
un rectangle supplémentaire \'a proximit\'e de 1. La m\'ethode du trap\'eze est une m\'ethode hybride des deux premi\`ères, est tr\'es proches de leurs valeurs. Cependant, la vitesse de convergence 
n'est pas satisfaisante.

\begin{center}
	\begin{tabular}{ | l | c | c | c | r| }
		 \hline
					& Rect \`a gauche 	& Rect \`a droite 	& Trap\`eze 		\\ \hline
			N = 101 	& 0.588234190031346 	& 0.5596004309853696 	& 0.5739173105083577 	\\ \hline
			N = 501 	& 0.6121548130243415 	& 0.5986303676112116 	& 0.6053925903177766 	\\ \hline
			N = 2001 	& 0.6222128575640632 	& 0.6152980965952546 	& 0.6187554770796588 	\\ \hline
			N = 10001 	& 0.6278537067166106 	& 0.6247228921422507 	& 0.6262882994294302 	\\ \hline
			N = 300001 	& 0.6316129255212698 	& 0.6310366283806264 	& 0.6313247769509484 	\\
		\hline
	\end{tabular}
\end{center}
Dans le tableau suivant on peut observer les valeurs avec la m\'ethode de Simpson et avec le changement de variable $\rho = 2$. On remarque que les valeurs obtenues sont bien plus proches de de la 
valeur attendue, afin de comparer l'efficacit\'e des deux m\'ethodes, dans les deux derni\`eres colonnes sont affich\'ees les valeurs des rapports des temps approch\'es et temps exact.
Il est clair que la m\'ethode du changement de variable est tr\'es efficace. On remarque \'egalement que la valeur la plus proche est celle obtenue avec N = 100, elle est d'ailleurs quasiment exacte,
On peut sugg\'erer que le fait que la perte de pr\'ecision avec l'augmentation du nombre de points \'evalu\'es provient du fait qu\'a chaque op\'eration sur des nombres \'a virgule flottante 
r\'ealis\'ee par l'ordianteur, il y a une perte d'information sur les nombres \'evalu\'es, ainsi ces pertes tr\'es locales peuvent \^etre observ\'ees avec un nombre de points suffisament important.

\begin{center}
	 \begin{tabular}{|l|c|c|c|c|r|}
		 \hline
					& Simpson 		 & Chgmt var. 		 & Simpson/$\frac{2}{\sqrt{10}}$ & Chgmt var./$\frac{2}{\sqrt{10}}$\\ \hline
			N = 101		& 0.5429105877244202	 & 0.632455532033676	 & 0.08584170115149097	 & 0.10000000000000002 \\ \hline 
			N = 501	 	& 0.5915569042287318	 & 0.6324555320336555	 & 0.09353335914804418	 & 0.09999999999999677 \\ \hline 
			N = 2001	& 0.6118405759154913	 & 0.6324555320337623	 & 0.09674048924010567	 & 0.10000000000001365 \\ \hline 
			N = 10001	& 0.6231962142068161	 & 0.6324555320339558	 & 0.09853597330438613	 & 0.10000000000004425 \\ \hline 
			N = 300001	& 0.6307602576051508	 & 0.6324555320266917	 & 0.099731953577341	 & 0.0999999999988957 \\ \hline 
	 \end{tabular}
\end{center}


\newpage
Les valeurs obtenues avec les m\'ethodes des rectangles ne sont pas affich\'ees mais comme toutes les valeurs obtenues dans ce document, elles peuvent \^etre reproduites et \'egalement export\'ees
au format \LaTeX depuis : \url{ github.com/DavyL/CalculTpsDescente/blob/master/main.py }
\\
Etude de la fonction : $f(x) = \sqrt{x}$
\begin{center}
	 \begin{tabular}{|l|c|c|c|c|r|}
		 \hline
					& Trap\`eze 		 & Simpson 		 & Chgmt var. \\ \hline
			N = 101	 	& 0.4414629538811862	 & 0.4104369376355152	 & 0.5785154925953274 \\ \hline 
			N = 501	 	& 0.485809387840139	 & 0.46570869302794915	 & 0.5785217623125455 \\ \hline 
			N = 2001	& 0.5127500044321911	 & 0.4986240922028768	 & 0.5785220112658342 \\ \hline 
			N = 10001	& 0.5344815065700885	 & 0.5250505889294617	 & 0.5785220272494653 \\ \hline 
			N = 300001	& 0.5596944890057428	 & 0.5556663980153529	 & 0.5785220279112407 \\ \hline 
	 \end{tabular}
\end{center}

\begin{figure}
  \includegraphics[scale = 0.5]{figures/figure2.pdf}
  \includegraphics[scale = 0.5]{figures/figure3.pdf}
  \caption{$x \mapsto \sqrt(x)$ et $x \mapsto \frac{1}{2}x^{\frac{3}{2}}(5 - 3x)$}
\end{figure}
Etude de la fonction : $f(x) = \frac{1}{2}x^{\frac{3}{2}}(5 - 3x)$	
On remarque ici que certaines valeurs ne sont pas d\'efinies avec le changement de variable, En effet, le programme \`a partir d'un certain rang, consid\`ere r\'ealiser une division par z\'ero. 
\begin{center}
	 \begin{tabular}{|l|c|c|c|c|r|}
		 \hline
					& Trap\`eze 		 & Simpson 		 & Chgmt var. \\ \hline
			N = 101	 	& 0.6260184369409418	 & 0.5834531246438184	 & 0.8021436648059572 \\ \hline 
			N = 501	 	& 0.6844340936028838	 & 0.658521444514206	 & non d\'efinie \\ \hline 
			N = 2001	& 0.7188625645940457	 & 0.7009068135150682	 & non d\'efinie \\ \hline 
			N = 10001	& 0.7464279324772518	 & 0.7344868671634918	 & non d\'efinie \\ \hline 
			N = 300001	& 0.7783351590003321	 & 0.7732398139627539	 & non d\'efinie \\ \hline 
	 \end{tabular}
\end{center}



\end{document}
