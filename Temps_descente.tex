\documentclass[a4paper,10pt]{article}
\usepackage[]{inputenc, amssymb, amsmath, amsthm}

%opening
\title{Calcul d'un temps de descente}
\author{DAVY L\'eo, CARPENTIER Florian}

\begin{document}

\maketitle
\newtheorem{theorem}{Theor\`eme}
\begin{abstract}
Nous allons ici vous pr\'esenter la math\'ematisation de l'un des sujets du projet. Celui-ci a des applications concr\`etes, notamment dans le milieu de l'a\'eronautique, par exemple
pour calculer les meilleures trajectoires de descente vers les aéroports. Cependant, la résolution de ce probl\`eme date de bien avant l'a\'eronautique, en 1638, Galil\'ee est le premier \`a s'int\'eresser
\`a ce probl\`eme. Jean Bernoulli sera le premier \`a r\'esoudre ce probl\`eme en 1696, des solutions de Newton, Leibnitz et Jacques Bernoulli seront aussi retenues \`a la suite d'un d\'efi lanc\'e
par Jean Bernoulli. La solution au probl\`eme est appel\'ee courbe de brachistochrone, c'est un arc de cycloïde. Ces \'etudes auront permis de d\'evelopper le calcul diff\'erentiel et variationnel.
\end{abstract}
\section{\'Etude m\'ecanique du probl\`eme}
Nous allons maintenant \'etudier une approche m\'ecanique du probl\`eme. On peut l'assimiler \`a une bille l\^ach\'ee dans un toboggan avec certains param\`etres, le toboggan d\'emarre en $(0,0)$
et s'arrête en $(1,1)$, (sans pertes de g\'en\'eralit\'es). On a donc $y : [0,1]\longrightarrow \mathbb{R}$ avec $y(0) = 0, y(1) = 1$ et $y$ continue. La bille est \'egalement l\^ach\'ee sans vitesse initiale.
On l'assimile \`a un point de masse m et on n\'egligera les frottements. L'abscisse curviligne de la bille sera not\'ee $S$.
\newline
On applique \`a ce syst\`eme un PFD et on remarque que la r\'eaction du toboggan ne travaille pas. On a ainsi :
\begin{equation}
 E_c(t) = \frac{1}{2}m\Big(\frac{dS}{dt}\Big)^2, \text{ et } E_p(t) = -mgy(x(t))
\end{equation}
Avec la loi de conservation de l'\'energie et les conditions initales on a :
\begin{equation}
 E_c(t) + E_p(t) = E_c(0) + E_p(0) = 0 = \frac{1}{2}m\Big(\frac{dS}{dt}\Big)^2 - mgy(x(t)) 
\end{equation}
\begin{equation}
 \frac{dS}{dt}=\sqrt{\frac{2mgy}{m}} = \sqrt{2gy} = S'(t)
\end{equation}
On obtient donc, avec un changement de variable la formule suivante :
\begin{equation}
\label{integrale}
 T(y) - T(0) = \int_0^{T(y)} dt = \int_0^{l(y)} \frac{dS}{\sqrt{2gy}}
\end{equation}
Par ailleurs, avec le th\'eor\`eme de Pythagore on obtient :
\begin{equation}
 dS = \sqrt{(dx)^2 + (dy)^2} = \sqrt{1 + \Big(\frac{dy}{dx}\Big)^2}dx = \sqrt{1 + \Big(y'(x)\Big)^2}dx
\end{equation}
Avec l'expression pr\'ecedente et \ref{integrale} on obtient finalement :
\begin{equation}
 T(y) = \int_0^1 \frac{\sqrt{1 + \Big(y'(x)\Big)^2}}{\sqrt{2gy}}dx
\end{equation}
Cependant l'expression pr\'ecedente pr\'sente des probl\`emes de singularit\'e en 0. En effet, on sait, qu'en 0, on a $y(0) = 0$ donc l'expression \`a int\'egrer  va varier tr\`es rapidement
\`a proximité de l'origine. Mais aussi, le calcul va d\'ependre de la d\'eriv\'ee de $y$ qui n'est pas suppos\'ee connue. Afin de r\'esoudre cette \'equation, qui n'admet pas forc\'ement de solution
analytique, il faut donc recourir \`a des m\'ethodes num\'eriques. 

\section{M\'ethode de r\'esolution ouverte}
La singularit\'e apparaissant en 0, on va utiliser une m\'ethode dite ``ouverte'' dans laquelle nous allons \'etudier l'int\'egrale sans calculer la valeur de la fonction \`a int\'egrer en 0 en utilisant
la m\'ethode vue en cours du point milieu.
\newline
On supposera dans cette partie que $y\in \mathcal{C}^1$ et que $y(x) > 0$, pour tout $x \neq 0$.
Pour simplifier les notations, on pose
\begin{equation}
 f(x) := \frac{\sqrt{1+(y'(x))^2}}{\sqrt{2gy(x)}}
\end{equation}
En notant $T_N(y)$ la valeur de $T(y)$ avec la m\'ethode du point milieu avec un pas de $1/N$ on obtient:
\begin{equation}
 T(y) \simeq T_N(y) := \frac{1}{N}\sum_{i = 0}^{N-1} f\Big(\frac{2i + 1}{2N}\Big)
\end{equation}
\begin{theorem}
 Si $f$ est de la forme $f(x) = x^{-\beta} + g(x)$ avec $g$ une fonction r\'eguli\`ere et $0 < \beta < 1$, Alors la m\'ethode du point milieu est d'ordre $1 - \beta$. 
\end{theorem}

\underline{Remarque : } $g$ r\'eguli\`ere signifie que $g$ est, au moins, partout $\mathcal{C}^1$, la fonction f peut donc repr\'esenter assez fid\`element un grand nombre de fonctions.
\begin{proof}
 Nous souhaitons mesurer l'erreur entre la m\'ethode exacte et la m\'ethode du point milieu.
 \begin{equation}
  |T(y) - T_N(y)| = |\int_0^\frac{1}{N}f(x)dx - \frac{1}{N}f\Big(\frac{1}{2N}\Big) + \int_\frac{1}{N}^1f(x)dx - \frac{1}{N}\sum_{i=1}^{N-1}\Big(\frac{2i + 1}{2N}\Big)|
 \end{equation}
 On applique l'in\'egalit\'e triangulaire
 \begin{equation}
  |T(y) - T_N(y)| \leq |\int_0^\frac{1}{N}f(x)dx - \frac{1}{N}f\Big(\frac{1}{2N}\Big)| + |\int_\frac{1}{N}^1f(x)dx - \frac{1}{N}\sum_{i=1}^{N-1}\Big(\frac{2i + 1}{2N}\Big)|
 \end{equation}
Par ailleurs,
\begin{equation}
\label{firstpart}
 \int_0^{\frac{1}{N}}f(x)dx = \int_0^{\frac{1}{N}} x^{-\beta} + g(x)dx = \frac{x^{-\beta + 1}}{-\beta + 1} + \int_0^{\frac{1}{N}}g(x)dx = \mathcal{O}(N^{\beta - 1})
\end{equation}
On remarque dans l'expression pr\'ecedente qu'il est n\'cessaire d'avoir $\beta \neq 0$ afin de ne pas faire de division par z\'ero.
Il nous reste donc \`a majorer le second terme, d'apr\`es le cours, la m\'ethode du point milieu est d'ordre $p = 1$ et d'apr\`es le th\'eor\`eme 4, il existe une constante $ C > 0$, telle que,
en posant $J_i = [\frac{2i-1}{2N},\frac{2i+1}{2N}], i \in [ 1,..., N-1]$ on obtient :
\begin{equation}
\begin{align}
 |\int_{J_i} f(x)dx - \frac{1}{N}f\Big(\frac{i}{N}\Big)| &\leq C(\frac{1}{N})^3 \sup_{x \in J_i}|f''(x)|\\
						 &\leq \frac{C}{N^3}(\| -\beta(-\beta - 1)x^{-\beta - 2} + g''(x)  \|_{\infty, J_i} \\
						 &\leq C N^{\beta - 1}i^{-\beta - 2} + \|\frac{C}{N^3}g''(x)  \|_{\infty, J_i} \\
\end{align}
\end{equation}
On a aussi :
\begin{equation}
 \begin{align} 
 |\int_\frac{1}{N}^1f(x)dx - \frac{1}{N}\sum_{i=1}^{N-1}f\Big(\frac{2i + 1}{2N}\Big)| &=  |\sum_{i=1}^{N-1}\int_{J_i} f(x)dx - \frac{1}{N}f\Big(\frac{2i + 1}{2N}\Big)|\\
									     &\leq  \sum_{i=1}^{N-1}|\int_{J_i} f(x)dx - \frac{1}{N}f\Big(\frac{2i + 1}{2N}\Big)|\\
									     &\leq C N^{\beta - 1} \sum_{i=1}^{N-1}i^{-\beta - 2} + \frac{C}{N^3}\sum_{i=1}^{N-1} \|g''(x)  \|_{\infty, J_i}
 \end{align}
\end{equation}
Or,
\begin{equation}
 \|g''(x)  \|_{\infty, J_i} \leq \|g''(x)  \|_{\infty, [0,1]}, \forall i
\end{equation}
Donc
\begin{equation}
 \sum_{i=1}^{N-1}\|g''(x)  \|_{\infty, J_i} \leq \sum_{i=1}^{N-1}\|g''(x)  \|_{\infty, [0,1]} = (N-1)\|g''(x)  \|_{\infty, [0,1]} 
\end{equation}
Et par ailleurs,
\begin{equation}
 0 < \sum_{i=1}^{N-1}i^{-\beta - 2} \leq \sum_{i=1}^{N-1}i^{- 2} \leq \sum_{i=1}^{\infty}i^{- 2} = \frac{\pi ^2}{6}  
\end{equation}
finalement :
\begin{equation}
\begin{align}
 |\int_\frac{1}{N}^1f(x)dx - \frac{1}{N}\sum_{i=1}^{N-1}f\Big(\frac{2i + 1}{2N}\Big)| &\leq C N^{\beta - 1} \frac{\pi ^2}{6}  + \frac{C}{N^2}\|g''(x)  \|_{\infty, [0,1]} 
									     &= \mathcal{O}(N^{\beta - 1}) 
\end{align}
\end{equation}
 En combinant \ref{firstpart} et l'expression pr\'ecedente on obtient bien que la m\'ethode est d'ordre $1- \beta$. Le th\'eor\`eme est donc bien d\'emontr\'e.
\end{proof}
Ce r\'esultat nous assure que nous avons au moins une solution num\'erique, cependant , cette m\'ethode n'\'etant pas tr\`es efficace, nous allons essayer dans la suite de trouver une m\'ethode plus efficace.

\section{R\'esolution avec un changement de variable}
Nous allons dans cette partie consid\'erer que le comportement de la fonction $y$ est connu en 0 et est de la forme
\begin{equation}
 y(x)\sim_0 c.x^{\alpha} \text{, avec } \beta = \begin{cases}
						    1 - \frac{\alpha}{2} &\text{, si }\alpha < 1\\
						    \frac{\alpha}{2}	 &\text{, si } 1 < \alpha < 2\\
						 \end{cases}
\end{equation}
Et on pose $x = u^\rho$, avec $\rho = \frac{1}{1 - \beta}$.
\begin{equation}
 \frac{dx}{du} = \rho u^{\rho - 1}
\end{equation}
On a donc
\begin{equation}
 T(y) = \int_0^1f(x)dx = \int_0^1f(u^\rho)\rho u^{\rho - 1} du = \rho \int_0^1f(u^\rho) u^{\rho - 1} du
\end{equation}
On applique maintenant la m\'ethode du point milieu et on obtient directement 
\begin{equation}
 T(y) \simeq \frac{\rho}{N}\sum_{i=0}^{N-1}f\Bigg(\Big(\frac{2i + 1}{2N}\Big)^{\rho}\Bigg)\Big(\frac{2i + 1}{2N}\Big)^{\rho - 1}
\end{equation}
Cette m\'ethode est d'ordre $\rho - 1$.
\section{Comparaison des deux m\'ethodes}
La m\'ethode du changementde variable est plus efficace si 
\begin{equation}
 \rho - 1 = \frac{\beta}{1-\beta} > 1 - \beta
\end{equation}
Comme $0 < \beta < 1$, l'in\'egalit\'e pr\'ecedente est toujours v\'erifi\'ee . Nous allons maintenant comparer les deux m\'ethodes sur des plusieurs exemples.
\newline
\underline{Cas d'un toboggan de type $y(x) = x$}: Dans ce cas on a $\alpha = 1$ et $\beta = \frac{1}{2}$, donc la premi\`ere m\'ethode est d'ordre $\frac{1}{2}$ et la seconde est d'ordre 2. 
\newline
\underline{Cas d'un toboggan de type $y(x) = \sqrt{x}$}: Dans ce cas on a $\alpha = \frac{1}{2}$ et $\beta = \frac{3}{4}$, donc la premi\`ere m\'ethode est d'ordre $\frac{1}{4}$ et la seconde est d'ordre 4.
\newline
\underline{Cas d'un toboggan de type $y(x) = \frac{1}{2}x^{\frac{3}{2}}(5-3x)$}: Dans ce cas on a ( au voisinage de 0 ) $\alpha = \frac{3}{2}$ et $\beta = \frac{3}{4}$, donc la premi\`ere m\'ethode est d'ordre $\frac{1}{4}$ et la seconde est d'ordre 4.
\newline
Ainsi, la seconde m\'ethode est bien plus efficace que la premi\`ere, cela s'explique par le fait que le changement de variable permet d'\'eviter la singularit\'e en 0.


\end{document}
